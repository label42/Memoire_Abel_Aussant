---
title: "Analyses_differents_matching"
author: "Abel AUSSANT"
date: "13/05/2022"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)

library(tidyverse)
library(here)
library(MatchIt)
library(cobalt)
library(ggplot2)
library(pwr)
library(gtsummary)
library(gt)


source(here("02_import", "import_bases.R"))

source(here("03_scripts", "gestion_NA_matching.R"))

list_var_match <- c("stream_spe", "SEXE_r", "AGE", "CRITREVENU_r", "PCS_MENAGE", "DIPLOME_r", 
                    "naiss_parents", "DIPLOME_pere", "DIPLOME_mere", "VITENCOUPLE_r", 
                    "music_amateur", "freq_tv", "equip_tv", "clip_tv", "freq_film", 
                    "film_stream_VOD", "film_stream_autre", "nbr_genre_film", "equip_serie", 
                    "serie_stream_VOD", "serie_replay", "info_internet", "musee_art_12m", 
                    "galerie_12m", "freq_internet", "reseaux_sociaux", "culture_en_ligne", 
                    "tv_enfance", "audivisuel_nonFR")

PC18_to_m <- clear_NA_to_m(PC18, list_var_match)

model_matching <- as.formula("stream_spe ~ SEXE_r + AGE + CRITREVENU_r + PCS_MENAGE + DIPLOME_r + 
                         naiss_parents + DIPLOME_pere + DIPLOME_mere + VITENCOUPLE_r + 
                         music_amateur + freq_tv + equip_tv + clip_tv + freq_film + 
                         film_stream_VOD + film_stream_autre + nbr_genre_film + equip_serie + 
                         serie_stream_VOD + serie_replay + info_internet + musee_art_12m + 
                         galerie_12m + freq_internet + reseaux_sociaux + culture_en_ligne + 
                         tv_enfance + audivisuel_nonFR")

fct_nbr_remise <- function(matching, d, var_match){
  match_matrix <- as.data.frame(matching$match.matrix) %>%
  mutate(across(everything(),as.numeric))
match_count <- as.data.frame(table(unlist(match_matrix)))
match_count <- match_count[order(match_count$Freq, decreasing = T),]


match_count[1:100,]

plot_nbr_remise <- ggplot(match_count, aes(reorder(Var1, Freq), y = Freq)) +
    geom_jitter()

most_matched <- as.character(match_count$Var1[1:10])

print(d[most_matched, var_match])

return(plot_nbr_remise)
}


```

Ce document vise à comparer différents paramètres pour la mise en œuvre du matching afin de sélectionner celui produisant le mailleur compromis possible entre équilibrage des covariables et taille de l'échantillon.

# Matching 1 pour 1 sans remise, aucune contrainte sur des variables spécifiques

```{r 1:1_sans_remise}
res_match_1to1_nore <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = FALSE,
)

love.plot(res_match_1to1_nore, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

```

Ce matching simple ne nécessite pas d'investigation plus poussée, il peut immédiatement être écarté des candidats. On voit que la qualité d'équilibrage est très mauvaise pour de nombreuses variables dont l'âge.

On en conclut que le matching sans remises n'est probablement pas une bonne stratégie dans notre cas.

# Matching 1 pour 1 avec remise, aucune contrainte sur des variables spécifiques

```{r 1:1_remise}
res_match_1to1_re <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
)

love.plot(res_match_1to1_re, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

bal.tab(res_match_1to1_re)

fct_nbr_remise(res_match_1to1_re, PC18_to_m, list_var_match)

```

Le love plot comparant l'échantillon apparié et l'échantillon de départ montre une qualité d'équilibrage relativement bonne pour l'ensemble des co-variables. En revanche, la taille de l'échantillon apparait comme problématique. En effet, seuls 1220 individus contrôles ont été inclus dans l'échantillon, ce qui peut sans doute être amélioré sans perdre en qualité d'équilibrage. 

(*Pas sûr à 100% de l'interprétation de l'ESS*) Pire l"effective sample size" qui est une mesure de la taille d'un échantillon hypothétique non pondéré par les poids d'appariement (remise) nous indique un échantillon de 551 individus. Autrement dit, si on prend en compte le fait que certains individus ont un poids plus faible du fait qu'ils ont été utilisés plusieurs fois, alors on arrive à un échantillon de 551 individus. Cela pourrait poser des problèmes de précision des estimateurs.

# Matching 3 pour 1 avec remise, aucune contrainte sur des variables spécifiques

```{r 3:1_remise}
res_match_3to1_re <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 3
)

love.plot(res_match_3to1_re, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

bal.tab(res_match_3to1_re)

fct_nbr_remise(res_match_3to1_re, PC18_to_m, list_var_match)

```

Pour remédier au problème de précision des estimateurs, on peut décider de matcher chaque individu traité avec plusieurs individus contrôles. Cela a pour effet d'augmenter le groupe contrôle, mais peut avoir un effet néfaste sur l'équilibrage. Avec un matching 3 pour 1, toujours avec remise, on obtient un groupe contrôle de 2339 individus distincts. Si on prend en compte les remises et qu'on calcule un échantillon effectif théorique, on arrive alors à 838 individus. L'équilibrage ne semble globalement pas avoir été perturbé outre mesure.

# Matching 5 pour 1 avec remise, aucune contrainte sur des variables spécifiques

```{r 5:1_remise}
res_match_5to1_re <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 5
)

love.plot(res_match_5to1_re, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

bal.tab(res_match_5to1_re)

fct_nbr_remise(res_match_5to1_re, PC18_to_m, list_var_match)

```

En passant à 5 pour 1, on augmente encore un peu l'ESS. Il faut maintenant investiguer plus avant la qualité de l'équilibrage. Regardons d'abord le support commun.

```{r test_equilibrage_1}
#Très bon. Petit soucis de support commun à la fin de la distribution qui nous fait perdre quelques individus.
bal.plot(res_match_5to1_re, var.name = "distance", which = "both",
         type = "histogram", mirror = TRUE)

bal.plot(res_match_5to1_re, var.name = "distance", which = "both",
         type = "density", mirror = F)
```

On voit apparaitre un problème de support commun au niveau de propensity score les plus élevés dans le groupe traité. Cela signifie qu'il n'existe aucun individu proche dans le groupe contrôle, il peut être judicieux de supprimer ces individus traités ne disposant pas d'homologues non traités. On perd en représentativité du groupe traité, mais on réduit le biais. Voyons combien on perd d'individus.

```{r}

res_match_5to1_re <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 5, discard = "treated"
)

bal.tab(res_match_5to1_re)

fct_nbr_remise(res_match_5to1_re, PC18_to_m, list_var_match)

```

Seuls 25 individus étaient concernés par ces problèmes de support commun. Un effet de bord intéressant est par ailleurs intervenu, l'ESS a augmenté pour monter à environ 1040 individus. Cela est dû au fait que des individus contrôle matchés de nombreuses dans les régions limites du support commun ne sont plus remis autant de fois qu'auparavant.

Une fois le problème du support commun résolu, on peut essayer de regarder de plus près l'équilibrage de certaines variables clefs, comme l'âge par exemple.

```{r}
bal.plot(res_match_5to1_re, var.name = "AGE")

```

L'observation unidimensionnelle par la différence de moyenne standard peut cacher des écarts importants à certains endroits de la distribution. C'est le cas pour l'âge, où les moins de 25 sont sur-représentés dans le groupe traité, avec que les 45 - 55 sont sous-représentés. Cela est particulièrement problématique dans notre cas, quand on sait que l'âge est le facteur de confusion le plus important pour les phénomènes qui nous occupent.

L'emploi de la méthode du caliper, qui permet de définir un écart d'âge maximum entre deux individus matchés, peut permettre de remédier au problème. Essayons.

```{r 5:1_remise_cali_age}
res_match_5to1_re_cali <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 5, caliper = c("AGE" = 2),std.caliper = F, discard = "treated"
)


bal.plot(res_match_5to1_re_cali, var.name = "AGE")

love.plot(res_match_5to1_re_cali, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

bal.tab(res_match_5to1_re_cali, binary = "std", thresholds = c(m = 0.05))

```

L'application de ce type de caliper a convenablement réglé le problème d'équilibrage sur notre variable d'âge. Il n'a par ailleurs pas sensiblement perturbé l'équilibrage de nos autres variables.
Si on veut essayer d'obtenir une meilleure qualité d'équilibrage sur l'ensemble des variables, on peut appliquer un caliper sur le propensity score lui-même, au risque de perdre des individus si aucun n'est trouvé dans la distance définie. Voyons comment notre échantillon se comporte si on procède ainsi, avec un écart maximal de 0.01 pour le propensity score (c'est-à-dire une probabilité de pratiquer le streaming de 1 %)

```{r}
res_match_5to1_re_cali <- matchit(model_matching
                      , data = PC18_to_m,
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 5, caliper = c(0.01,"AGE" = 2), std.caliper = F, discard = "treated"
)

love.plot(res_match_5to1_re_cali, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

bal.tab(res_match_5to1_re_cali)
```

Procéder ainsi nous oblige à nous délester de 112 individus traités supplémentaires, pour une amélioration de l'équilibrage non quantifiable à partir d'un seul love plot. Il serait peut-être préférable de s'assurer de l'équilibrage de certaines variables considérées comme particulièrement déterminantes et d'agir en conséquence plutôt que de raisonner au niveau de toutes les variables avec un caliper sur le propensity score.

Le diplômé apparait comme une autre variable très importante pour nous. Observons : 

```{r}
res_match_5to1_re_cali <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 5, caliper = c("AGE" = 2), std.caliper = F, discard = "treated"
)

bal.plot(res_match_5to1_re_cali, var.name = "DIPLOME_r", 
         type = "histogram", mirror = F)

bal.tab(res_match_5to1_re_cali, binary = "std", thresholds = c(m = 0.05))
```

En ce qui concerne le diplôme, l'écart de proportion entre les groupes est extrêmement faible, et ce pour toutes les modalités. La différence de proportion ajustée est toujours inférieure à 0.03, les standards de qualité généralement retenus étant à 0.05, on a ici un équilibrage de très bonne qualité.

Si on applique cette règle communément utilisée dans la littérature, seule une modalité, d'une de nos covariables dépasse le seuil, et cela de très peu : CS_mere_Artisant/commerçant  -0.0546. Au vu des standards observés dans les travaux consacrés mettant en œuvre la méthode, la qualité d'équilibrage obtenue ici est tout à fait acceptable et même très bonne.

Les poids issue du matching prennent en compte les remises, en pondérant plus faiblement les individus réutilisés de multiples fois, mais on peut tout de même se demander combien de fois les individus les plus matché le sont. Il ne faut pas oublier qu'on match chaque fois avec 5 individus contrôle, ce qui augmente mécaniquement le nombre de remise. Voici les 100 individus les plus matchés et leur caractéristiques.

```{r}
fct_nbr_remise(res_match_5to1_re_cali, PC18_to_m, list_var_match)

```

On voit que certains individus sont réutilisés jusqu'à 40 fois, sachant qu'ils sont toujours accompagnés de 4 autres individus. Je ne sais pas estimer à quel point cela est un problème.

On peut essayer de mettre en oeuvre une stratégie de matching différente qui limiterai le nombre de réutilisation. Par exemple en faisant un matching 5:1 et en authorisant un replacement de 15 maximum. Essayons et testons la qualité de l'équilibrage.

```{r}
res_match_5to1_re15max_cali <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 5, caliper = c("AGE" = 2), std.caliper = F, discard = "treated", reuse.max = 15

)

bal.tab(res_match_5to1_re15max_cali, binary = "std", thresholds = c(m = 0.05))

love.plot(res_match_5to1_re15max_cali, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

fct_nbr_remise(res_match_5to1_re15max_cali, PC18_to_m, list_var_match)

```

Des problèmes importants d'équlibrage apparaissent, notamment sur des variables concernant les pratiques culturelles qu'on considère comme centrale pour eviter les biais de selection (musee_art_12m, audiovisuel_nonFR, etc.)
L'ESS n'est pas meilleur. Peu d'interet.


Avec un ratio de 1:1

```{r}
res_match_1to1_re5max_cali <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 1, caliper = c("AGE" = 2), std.caliper = F, discard = "treated", reuse.max = 5

)

bal.tab(res_match_1to1_re5max_cali, binary = "std", thresholds = c(m = 0.05))

love.plot(res_match_1to1_re5max_cali, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

fct_nbr_remise(res_match_1to1_re5max_cali, PC18_to_m, list_var_match)

```

L'equilibrage est ici grandement amélioré. Les problèmes restant sont marginaux (SMD très proche de 0.05, rappelons que beaucoup de papier utilise un treshold de 0.1, on est donc déjà plus rigoureux que la norme en utilisant 0.5) et concernent seulement quelques modalités de variables d'origines sociale assez peu impactante dans les modèles d'estimation du streaming ou des goûts.

On s'en sort avec un ESS de 828, ce qui est tout de même asez faible. A discuter.

Voyons ce que ça peut donner avec 10 réutilisation max.

```{r}
res_match_1to1_re10max_cali <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 1, caliper = c("AGE" = 2), std.caliper = F, discard = "treated", reuse.max = 10

)

bal.tab(res_match_1to1_re10max_cali, binary = "std", thresholds = c(m = 0.05))

love.plot(res_match_1to1_re10max_cali, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

fct_nbr_remise(res_match_1to1_re10max_cali, PC18_to_m, list_var_match)
```

La qualité d'équilibrage baisse et l'ESS également. Sans intéret.

Voyons avec 3 réutilisation max.

```{r}
res_match_1to1_re3max_cali <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 1, caliper = c("AGE" = 2), std.caliper = F, discard = "treated", reuse.max = 3

)

bal.tab(res_match_1to1_re3max_cali, binary = "std", thresholds = c(m = 0.05))

love.plot(res_match_1to1_re3max_cali, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

fct_nbr_remise(res_match_1to1_re3max_cali, PC18_to_m, list_var_match)
```

ESS plus élevé mais equilibrage mauvais pour certaines covariables importantes.

Voyons avec un matching 1:1 sans contrainte de réutilisation

```{r}
res_match_1to1_re_cali <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 1, caliper = c("AGE" = 2), std.caliper = F, discard = "treated"

)

bal.tab(res_match_1to1_re_cali, binary = "std", thresholds = c(m = 0.05))

love.plot(res_match_1to1_re_cali, 
          drop.distance = TRUE, 
          var.order = "adjusted",
          abs = TRUE,
          thresholds = c(m = .05), 
          binary = "std",
          continuous = "std")

fct_nbr_remise(res_match_1to1_re_cali, PC18_to_m, list_var_match)
```

Moins bon que quand on utilise 5 remise maximum. 

# Conclusion

Le choix semble devoir se faire entre :
 - matching 5:1, avec réutilisaion (sans limitte), avec caliper 2 sur l'âge
 - matching 1:1, avec réutilisation (max 5), avec caliper sur l'âge
 
Voir conseil stack exchange pour prise de décision.

On peut d'abord effectuer un test de puissance pour savoir si l'ESS obtenu suffit à estimer l'effet qu'on envisage de mesurer.

On peut faire ce test pour un écart de proportion entre deux groupes.

Ici, on cherche a savoir combien d'individu faudrait-il dans un groupe controle pour observer une différence de proportion pour une variable qualitative (pour nous, la proportion d'individu écoutant tel style de musique vs n'écoute pas), à partir d'un groupe traité de taille connu, pour un effet d'une taille de 0.2 (d de cohen > 0.2 au moins), pour une P value d'au moins 0.01 et avec une probabilité de 0.95 de mesurer l'effet.

On connait bien la taille de notre groupe traité (n = 2245, les streameurs). 

```{r}

pwr.2p2n.test(h = 0.2, n1 = 2245, power = 0.95, sig.level = 0.01)
```

On obtient n2 = 556. Cela signifie qu'il faudrait 556 individu dans le groupe controle pour avoir 95% de chance mesurer un effet de taille d de cohen = 0,2 avec p value = 0.01, pour un echantillion traité de 2245. Les deux methode de matching dépasse largement cette ESS pour le groupe contrôle.

On peut faire un test similaire pour une différence de moyenne (moyenne de nombre de styles écouté chez nous).

```{r}
pwr.t2n.test(n1 = 2245, d = 0.2, power = 0.95)
```
A nouveau, pour observer une différence de moyenne entre les deux groupe (groupe traité n = 2245), avec un effet de taille t-test > 0.2 et une puissance de 0.95, il faudrait 380 individus dans le groupe contrôle minimum. 

On peut aussi le faire pour un modèle de regression

Dans cette fonction, u represent le nombre de coefficient dans la regression servant à estimer l'effet du stream sur une variable, f2 le R² du modèle, sig.level la précision à laquelle on veut estimer l'effet (p value), et power la probabilité qu'on à lquelle on souhaite pouvoir mesurer un effet, ici 95%.

```{r}
pwr.f2.test(u = 80, f2 = 0.3/(1 - 0.3), sig.level = 0.01, power = 0.95)
```

On obtient en v = 132. Cela signifit qu'il faut un effectif de 132 individus minimum pour avoir 95% de chances de mesurer l'effet d'une variables (avec une précision de P = 0.01) dans un modèle à 80 variables avc un r² de 0.3.

Prenant en considération ces tests de puissance, les deux méthodes de matching candidates sont susceptibles de contenire assez d'information pour estimer des effets de tail considéré comme faibles, du streaming sur nos variables d'interet. 

## Template matching

Une autre solution proposé par Noah (createur du package MatchIt) sur Cross validated peu être d'utiliser de Template matching, qui va maximiser le nombre d'individus dans le groupe contrôle sous certaines contrainte d'equilibrage.

```{r}
library(Rglpk)
library(gurobi)

res_match_template <- matchit(model_matching,
                  data = PC18_to_m, method = "cardinality",
                  estimand = "ATT", ratio = NA, discard = "none", 
                  tols = c(0.05), std.tols = c(T), solver = "gurobi", time = 300)


bal.tab(res_match_template, binary = "std", thresholds = c(m = 0.05))

bal.plot(res_match_template, var.name = "AGE")

```

Cette méthode permet en effet d'obtenir 1415 individus dans l'echantillion, ce qui est supérieure de 300 à ce qu'on obtenait en utilisant le matching par propensity score avec remise 5:1. En revanche l'equilibrage de l'age est ici très problématique. On ne peut aps utiliser de caliper dans cette méthode. ON peut faire soit un matching exacte sur l'age, soit mettre une STD mean dif plus faible.

```{r}

res_match_template <- matchit(model_matching,
                  data = PC18_to_m, method = "cardinality",
                  estimand = "ATT", ratio = NA, discard = "none", exact = "AGE", 
                  tols = c(0.05), std.tols = c(T), solver = "gurobi", time = 300)


```

Malheureusement il n'existe pas de solution qui satisface nos conditions d'age exacte et de std mean diff < 0.05 sur toutes les autres cov.

```{r}



tols_all_var = c(0.05, 0.01, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05)

std.tols_all_var = c(T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T)

res_match_template <- matchit(model_matching,
                  data = PC18_to_m, method = "cardinality",
                  estimand = "ATT", ratio = NA, discard = "none",  
                  tols = tols_all_var, std.tols = std.tols_all_var, solver = "gurobi", time = 300)

bal.tab(res_match_template, binary = "std", thresholds = c(m = 0.05))

bal.plot(res_match_template, var.name = "AGE")

```

Indiquer une STD mean dif plus faible pour l'age ne regle en rien le problème des écarts à certains endroit de la distribution. Une solution peut être de récouper l'age en tranche, a s'assure ainsi un équilibre dans chanque tranche

```{r}

tols_all_var = c(0.05, 0.005, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05)

std.tols_all_var = c(T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T)

res_match_template <- matchit(stream_spe ~ SEXE_r + AGE_5_r + CRITREVENU_r + PCS_MENAGE + DIPLOME_r + 
                         naiss_parents + DIPLOME_pere + DIPLOME_mere + VITENCOUPLE_r + 
                         music_amateur + freq_tv + equip_tv + clip_tv + freq_film + 
                         film_stream_VOD + film_stream_autre + nbr_genre_film + equip_serie + 
                         serie_stream_VOD + serie_replay + info_internet + musee_art_12m + 
                         galerie_12m + freq_internet + reseaux_sociaux + culture_en_ligne + 
                         tv_enfance + audivisuel_nonFR,
                  data = PC18_to_m, method = "cardinality",
                  estimand = "ATT", ratio = NA, discard = "none",  
                  tols = tols_all_var, std.tols = std.tols_all_var, solver = "gurobi", time = 300)

bal.tab(res_match_template, binary = "std", thresholds = c(m = 0.05))

bal.plot(res_match_template, var.name = "AGE_5_r")

```
De cette manière on peut obtenir une balance de l'age tout à fait similaire à ce qu'on obtenait avec un caliper de 2 sur l'age. 

Le resultats du matching est très bon, part construction tous les std mean dif sont en dessous de 0.05. Cela étant, on obtient une taille de groupe contrôle de 1214, ce qui est a peine mieux que ce qu'on obtenait avec les méthodes 5:1 avec replacement. A mon avis, on arrive aux limitte de notre échantillion, on peut surement pas faire beaucoup mieux que cela en terme de taille effective du groupe contrôle, 1200 environ. Cette taille est acceptable si on considère les tests de puissance effectué plus haut.

On peut tout de même essayer avec la méthode cardinality, qui va effectuer un matching 1:1 sans remise, en maximisant les nombre d'individu contrôle et traité sous contrainte de std min diff définit. On risque néamoins de perdre pas mal d'individus traité. Voyons :

```{r}

tols_all_var = c(0.05, 0.005, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05)

std.tols_all_var = c(T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T)

res_match_card <- matchit(stream_spe ~ SEXE_r + AGE_5_r + CRITREVENU_r + PCS_MENAGE + DIPLOME_r + 
                         naiss_parents + DIPLOME_pere + DIPLOME_mere + VITENCOUPLE_r + 
                         music_amateur + freq_tv + equip_tv + clip_tv + freq_film + 
                         film_stream_VOD + film_stream_autre + nbr_genre_film + equip_serie + 
                         serie_stream_VOD + serie_replay + info_internet + musee_art_12m + 
                         galerie_12m + freq_internet + reseaux_sociaux + culture_en_ligne + 
                         tv_enfance + audivisuel_nonFR,
                  data = PC18_to_m, method = "cardinality",
                  estimand = "ATT", ratio = 1,
                  tols = tols_all_var, std.tols = std.tols_all_var, solver = "gurobi", time = 900)

bal.tab(res_match_card, binary = "std", thresholds = c(m = 0.05))

```

On ne perd que 332 individu traité, pour gagner 1938 individu contrôle, matching 1:1 sans remise. L'équilibrage est par construction excellent. C'est peut-être la meilleure solution à envisager.

Essayons d'observer les caractéristiques de ces individus traité non matché.

```{r}
PC18_unmatched <- match.data(res_match_card)
PC18_unmatched <- filter(PC18_unmatched, PC18_unmatched$stream_spe == 1)
PC18_streameur <- filter(PC18_to_m, PC18_to_m$stream_spe == 1)
PC18_unmatched <- filter(PC18_streameur, !PC18_streameur$IDENT18 %in% PC18_unmatched$IDENT18)

theme_gtsummary_language("fr", decimal.mark = ",", big.mark = " ")

PC18_unmatched_s <- survey::svydesign(id = ~IDENT18, data = PC18_unmatched, weights = PC18_unmatched$POND)
PC18_streameur_s <- survey::svydesign(id = ~IDENT18, data = PC18_streameur, weights = PC18_streameur$POND)


tbl_unmatched <- PC18_unmatched_s %>%
  tbl_svysummary(
    include = c("SEXE_r", "AGE_5_r", "DIPLOME_r", "PCS_MENAGE",  "music_12m", "nbr_genre_music"), #L'ensemble des variables que l'on veut dans le tableau
    label = list(SEXE_r ~ "Sexe",
                 AGE_5_r ~ "Age",
                 DIPLOME_r ~ "Niveau de diplome"),
    missing = "ifany",
    statistic = list(all_categorical() ~ "{p} % N = {n_unweighted}",
                     all_continuous() ~ "{mean} ({sd})"),
    digits = list(all_categorical() ~ c(1,0))
  ) %>%
  modify_footnote(update = everything() ~ NA) %>%
  modify_header(label = "**Variables**", stat_0 ~ "**N = {N_unweighted}**")

 
tbl_streameur <-  PC18_streameur_s %>%
  tbl_svysummary(
    include = c("SEXE_r", "AGE_5_r", "DIPLOME_r", "PCS_MENAGE",  "music_12m", "nbr_genre_music"), #L'ensemble des variables que l'on veut dans le tableau
    label = list(SEXE_r ~ "Sexe",
                 AGE_5_r ~ "Age",
                 DIPLOME_r ~ "Niveau de diplome"),
    missing = "ifany",
    statistic = list(all_categorical() ~ "{p} % N = {n_unweighted}",
                     all_continuous() ~ "{mean} ({sd})"),
    digits = list(all_categorical() ~ c(1,0))
  ) %>%
  modify_footnote(update = everything() ~ NA) %>%
  modify_header(label = "**Variables**", stat_0 ~ "**N = {N_unweighted}**")

tbl_comp_unmatched <-
  tbl_merge(
    tbls = list(tbl_unmatched, tbl_streameur),
    tab_spanner = c("**Echantillon streameurs non matché**", "**Echantillon streameurs**")
  )

tbl_comp_unmatched

```



## Full matching

```{r}
library(optmatch)

res_match_full <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "full", distance = "glm",
                      caliper = c("AGE" = 2), std.caliper = F, discard = "treated", 
                      s.weights = PC18_to_m$POND)

                      
bal.tab(res_match_full, binary = "std", thresholds = c(m = 0.05))

bal.plot(res_match_full, var.name = "AGE_5_r")

```

ESS de 859, et balance mauvaise. Probablement pas approprié.

# Comparaison matching candidat, avec et sans poids de sondage

## Matching 5:1 replacement illimité, caliper

### Sans aucun poids de sondage pris en compte

```{r}
res_match_5to1_re_cali <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 5, caliper = c("AGE" = 2), std.caliper = F, discard = "treated"
)

res_match_5to1_re_cali

bal.tab(res_match_5to1_re_cali, binary = "std", thresholds = c(m = 0.05))
```

### Avec poids de sondage ajouté après calcul du propensity score

```{r}
res_match_5to1_re_cali <- matchit(model_matching
                      , data = PC18_to_m, 
                      method = "nearest", distance = "glm", replace = T,
                      ratio = 5, caliper = c("AGE" = 2), std.caliper = F, discard = "treated"
)

res_match_5to1_re_cali <- add_s.weights(res_match_5to1_re_cali, s.weights = "POND")

res_match_5to1_re_cali

bal.tab(res_match_5to1_re_cali, binary = "std", thresholds = c(m = 0.05))
```

### Avec poids de sondage pris en compte dans le calcule du propensity score

```{r}
res_match_5to1_re_cali <- matchit(model_matching
                      , data = PC18_to_m, s.weights = PC18_to_m$POND,
                      method = "nearest", distance = "glm", replace = T, 
                      ratio = 5, caliper = c("AGE" = 2), std.caliper = F, discard = "treated"
)

res_match_5to1_re_cali

bal.tab(res_match_5to1_re_cali, binary = "std", thresholds = c(m = 0.05))
```

## Matching template

### Matching sans aucune prise en compte des poids de sondages

```{r}
tols_all_var = c(0.05, 0.005, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05)

std.tols_all_var = c(T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T)

res_match_template_no_w <- matchit(stream_spe ~ SEXE_r + AGE_5_r + CRITREVENU_r + PCS_MENAGE + DIPLOME_r + 
                         naiss_parents + DIPLOME_pere + DIPLOME_mere + VITENCOUPLE_r + 
                         music_amateur + freq_tv + equip_tv + clip_tv + freq_film + 
                         film_stream_VOD + film_stream_autre + nbr_genre_film + equip_serie + 
                         serie_stream_VOD + serie_replay + info_internet + musee_art_12m + 
                         galerie_12m + freq_internet + reseaux_sociaux + culture_en_ligne + 
                         tv_enfance + audivisuel_nonFR,
                  data = PC18_to_m, method = "cardinality",
                  estimand = "ATT", ratio = NA, discard = "none",  
                  tols = tols_all_var, std.tols = std.tols_all_var, solver = "gurobi", time = 300)

res_match_template_no_w

bal.tab(res_match_template_no_w, binary = "std", thresholds = c(m = 0.05))
```

### Matching prise en compte des poids de sondages après matching

```{r}
tols_all_var = c(0.05, 0.005, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05)

std.tols_all_var = c(T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T)

res_match_template_w_after <- matchit(stream_spe ~ SEXE_r + AGE_5_r + CRITREVENU_r + PCS_MENAGE + DIPLOME_r + 
                         naiss_parents + DIPLOME_pere + DIPLOME_mere + VITENCOUPLE_r + 
                         music_amateur + freq_tv + equip_tv + clip_tv + freq_film + 
                         film_stream_VOD + film_stream_autre + nbr_genre_film + equip_serie + 
                         serie_stream_VOD + serie_replay + info_internet + musee_art_12m + 
                         galerie_12m + freq_internet + reseaux_sociaux + culture_en_ligne + 
                         tv_enfance + audivisuel_nonFR,
                  data = PC18_to_m, method = "cardinality",
                  estimand = "ATT", ratio = NA, discard = "none",  
                  tols = tols_all_var, std.tols = std.tols_all_var, solver = "gurobi", time = 300)

res_match_template_w_after <- add_s.weights(res_match_template_w_after, s.weights = "POND")


res_match_template_w_after


bal.tab(res_match_template_w_after, binary = "std", thresholds = c(m = 0.05))
```

### Matching prise en compte des poids de sondages avant matching

SMD = 0.05

```{r}
tols_all_var = c(0.05, 0.02, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,
  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05)

std.tols_all_var = c(T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T, T, T,
  T, T, T, T, T, T, T, T)

res_match_template_w_before <- matchit(stream_spe ~ SEXE_r + AGE_5_r + CRITREVENU_r + PCS_MENAGE + DIPLOME_r + 
                         naiss_parents + DIPLOME_pere + DIPLOME_mere + VITENCOUPLE_r + 
                         music_amateur + freq_tv + equip_tv + clip_tv + freq_film + 
                         film_stream_VOD + film_stream_autre + nbr_genre_film + equip_serie + 
                         serie_stream_VOD + serie_replay + info_internet + musee_art_12m + 
                         galerie_12m + freq_internet + reseaux_sociaux + culture_en_ligne + 
                         tv_enfance + audivisuel_nonFR,
                  data = PC18_to_m, s.weights = PC18_to_m$POND, 
                  method = "cardinality",
                  estimand = "ATT", ratio = NA, discard = "none",  
                  tols = tols_all_var, std.tols = std.tols_all_var, solver = "gurobi", time = 300)



res_match_template_w_before


bal.tab(res_match_template_w_before, binary = "std", thresholds = c(m = 0.05))
```


